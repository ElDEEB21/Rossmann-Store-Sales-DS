{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'rossmann-store-sales:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F109852%2F262482%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240926%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240926T200258Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Dd754629f0d748a5f7ec3282ad62606a547bc6b8e7396361e5e6427805d0e966dd5ebc627a82210335fd60c5f5714eb0c2a010c481c6794ce6e357e24f5ea59b8a20e1b82c4a95af17d40f0909625b73394c0f92542ef7bd7807e86734a2f851acb3408f988253f6cb9ae851e99352d4bdd43baf8b9e47a99e6ef9427d7928a314c6fe0203a3e4e4e83f66e719f0d5a2112f4cffc9a397a7b74dc05ba825d6aad55b757aa981592b9a73b8f4c92bb3e6238721ff6a66b27143a01d9f08ac9948ee1cfa383a82c9ee100e5f3bc49168b6085fea502772e7ee40868b691ced905ece2728fd26204b3a6e017ee259eab52aedcb66eb362c20f3f2566d86dd90610a6'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "ylJS3QAB78-M",
        "outputId": "73dd2272-7372-433d-8bb9-06f0a491dd44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ylJS3QAB78-M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rossmann-store-sales, 7240167 bytes compressed\n",
            "[==================================================] 7240167 bytes downloaded\n",
            "Downloaded and uncompressed: rossmann-store-sales\n",
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b28fc44",
      "metadata": {
        "id": "5b28fc44"
      },
      "outputs": [],
      "source": [
        "## sklearn -- Preprocessing & Tuning & Transformation\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "## sklearn -- metrics\n",
        "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
        "# Step 1: Import the necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score ,mean_absolute_error\n",
        "\n",
        "import joblib\n",
        "# Sample Data Preparation\n",
        "# Replace this with your actual data\n",
        "## sklearn -- Models\n",
        "## Xgboost\n",
        "from xgboost import XGBRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10ccb69e",
      "metadata": {
        "id": "10ccb69e"
      },
      "outputs": [],
      "source": [
        "\n",
        "Ross_df = pd.read_csv('/kaggle/input/rossmann-store-sales/train.csv', low_memory=False)\n",
        "Store_df = pd.read_csv('/kaggle/input/rossmann-store-sales/store.csv')\n",
        "Test_df = pd.read_csv('/kaggle/input/rossmann-store-sales/test.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrIhBwfj1Eob"
      },
      "id": "OrIhBwfj1Eob",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86aa6955",
      "metadata": {
        "id": "86aa6955",
        "outputId": "d0397a63-a96e-4aaa-868a-b771749f4fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
              "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
              "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
              "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
              "       'Promo2SinceYear', 'PromoInterval'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Load your dataset\n",
        "data = Ross_df.merge(Store_df, how='left', on='Store')\n",
        "data.to_csv('data.csv', index=False)\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "39DHDY2CYn_R",
        "outputId": "c69dd880-b34b-4394-c365-f20d4d184348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "id": "39DHDY2CYn_R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Store  DayOfWeek        Date  Sales  Customers  Open  Promo  \\\n",
              "0            1          5  2015-07-31   5263        555     1      1   \n",
              "1            2          5  2015-07-31   6064        625     1      1   \n",
              "2            3          5  2015-07-31   8314        821     1      1   \n",
              "3            4          5  2015-07-31  13995       1498     1      1   \n",
              "4            5          5  2015-07-31   4822        559     1      1   \n",
              "...        ...        ...         ...    ...        ...   ...    ...   \n",
              "1017204   1111          2  2013-01-01      0          0     0      0   \n",
              "1017205   1112          2  2013-01-01      0          0     0      0   \n",
              "1017206   1113          2  2013-01-01      0          0     0      0   \n",
              "1017207   1114          2  2013-01-01      0          0     0      0   \n",
              "1017208   1115          2  2013-01-01      0          0     0      0   \n",
              "\n",
              "        StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  \\\n",
              "0                  0              1         c          a               1270.0   \n",
              "1                  0              1         a          a                570.0   \n",
              "2                  0              1         a          a              14130.0   \n",
              "3                  0              1         c          c                620.0   \n",
              "4                  0              1         a          a              29910.0   \n",
              "...              ...            ...       ...        ...                  ...   \n",
              "1017204            a              1         a          a               1900.0   \n",
              "1017205            a              1         c          c               1880.0   \n",
              "1017206            a              1         a          c               9260.0   \n",
              "1017207            a              1         a          c                870.0   \n",
              "1017208            a              1         d          c               5350.0   \n",
              "\n",
              "         CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  \\\n",
              "0                              9.0                    2008.0       0   \n",
              "1                             11.0                    2007.0       1   \n",
              "2                             12.0                    2006.0       1   \n",
              "3                              9.0                    2009.0       0   \n",
              "4                              4.0                    2015.0       0   \n",
              "...                            ...                       ...     ...   \n",
              "1017204                        6.0                    2014.0       1   \n",
              "1017205                        4.0                    2006.0       0   \n",
              "1017206                        NaN                       NaN       0   \n",
              "1017207                        NaN                       NaN       0   \n",
              "1017208                        NaN                       NaN       1   \n",
              "\n",
              "         Promo2SinceWeek  Promo2SinceYear     PromoInterval  \n",
              "0                    NaN              NaN               NaN  \n",
              "1                   13.0           2010.0   Jan,Apr,Jul,Oct  \n",
              "2                   14.0           2011.0   Jan,Apr,Jul,Oct  \n",
              "3                    NaN              NaN               NaN  \n",
              "4                    NaN              NaN               NaN  \n",
              "...                  ...              ...               ...  \n",
              "1017204             31.0           2013.0   Jan,Apr,Jul,Oct  \n",
              "1017205              NaN              NaN               NaN  \n",
              "1017206              NaN              NaN               NaN  \n",
              "1017207              NaN              NaN               NaN  \n",
              "1017208             22.0           2012.0  Mar,Jun,Sept,Dec  \n",
              "\n",
              "[1017209 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f047898-e8be-4339-bdce-e992e3163944\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Customers</th>\n",
              "      <th>Open</th>\n",
              "      <th>Promo</th>\n",
              "      <th>StateHoliday</th>\n",
              "      <th>SchoolHoliday</th>\n",
              "      <th>StoreType</th>\n",
              "      <th>Assortment</th>\n",
              "      <th>CompetitionDistance</th>\n",
              "      <th>CompetitionOpenSinceMonth</th>\n",
              "      <th>CompetitionOpenSinceYear</th>\n",
              "      <th>Promo2</th>\n",
              "      <th>Promo2SinceWeek</th>\n",
              "      <th>Promo2SinceYear</th>\n",
              "      <th>PromoInterval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>5263</td>\n",
              "      <td>555</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>1270.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2008.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>6064</td>\n",
              "      <td>625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>570.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2007.0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>8314</td>\n",
              "      <td>821</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>14130.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>13995</td>\n",
              "      <td>1498</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>620.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2009.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2015-07-31</td>\n",
              "      <td>4822</td>\n",
              "      <td>559</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>29910.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017204</th>\n",
              "      <td>1111</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.0</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017205</th>\n",
              "      <td>1112</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>1880.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2006.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017206</th>\n",
              "      <td>1113</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>9260.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017207</th>\n",
              "      <td>1114</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>870.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017208</th>\n",
              "      <td>1115</td>\n",
              "      <td>2</td>\n",
              "      <td>2013-01-01</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>d</td>\n",
              "      <td>c</td>\n",
              "      <td>5350.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>Mar,Jun,Sept,Dec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1017209 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f047898-e8be-4339-bdce-e992e3163944')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f047898-e8be-4339-bdce-e992e3163944 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f047898-e8be-4339-bdce-e992e3163944');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f1ceb7b0-1019-4de7-99ef-9c4361a25652\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1ceb7b0-1019-4de7-99ef-9c4361a25652')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f1ceb7b0-1019-4de7-99ef-9c4361a25652 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bd541144-2772-4315-9d1f-f7515cfaca70\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bd541144-2772-4315-9d1f-f7515cfaca70 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64d0e54f",
      "metadata": {
        "id": "64d0e54f"
      },
      "outputs": [],
      "source": [
        "# Convert 'Date' column to datetime\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# Extract features from 'Date' column\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "data['WeekOfYear'] = data['Date'].dt.isocalendar().week.astype(int)\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data =data.drop(columns=['Date', ], axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655c622f",
      "metadata": {
        "id": "655c622f"
      },
      "source": [
        "#  Feature Engineer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad38ae39",
      "metadata": {
        "id": "ad38ae39"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Try to make some Feature Engineering --> Feature Extraction --> Add the new column to the main DF\n",
        "data[\"SalesPerCustomer\"]=np.where(data['Customers'] == 0, 0, data['Store'] / data['Customers'])\n",
        "\n",
        "data['SalesPerDistance'] = np.where(data['CompetitionDistance'] == 0, 0, data['Store'] / data['CompetitionDistance'])\n",
        "\n",
        "# %%\n",
        "# # Handling missing values for both features\n",
        "# data['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n",
        "# data['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
        "# data['Promo2SinceYear'].fillna(0, inplace=True)\n",
        "# data['Promo2SinceWeek'].fillna(0, inplace=True)\n",
        "\n",
        "# Merge CompetitionOpenSinceYear and CompetitionOpenSinceMonth into 'CompetitionOpenSince'\n",
        "data['CompetitionOpenSince'] = data['CompetitionOpenSinceYear']* data['CompetitionOpenSinceMonth']\n",
        "\n",
        "# Merge Promo2SinceYear and Promo2SinceWeek into 'Promo2Since'\n",
        "data['Promo2Since'] = data['Promo2SinceYear']  * data['Promo2SinceWeek']\n",
        "\n",
        "data = data.drop(columns=['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear'], axis=1)\n",
        "data =data.drop(columns=['Promo2SinceYear', 'Promo2SinceWeek',\"Promo2SinceWeek\"], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb0a071",
      "metadata": {
        "id": "bfb0a071",
        "outputId": "489af6e7-f1d7-44ae-dfa3-ca1ee5209502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Store  DayOfWeek  Sales  Customers  Open  Promo StateHoliday  \\\n",
              "0            1          4   5263        555     1      1            0   \n",
              "1            2          4   6064        625     1      1            0   \n",
              "2            3          4   8314        821     1      1            0   \n",
              "3            4          4  13995       1498     1      1            0   \n",
              "4            5          4   4822        559     1      1            0   \n",
              "...        ...        ...    ...        ...   ...    ...          ...   \n",
              "1017204   1111          1      0          0     0      0            a   \n",
              "1017205   1112          1      0          0     0      0            a   \n",
              "1017206   1113          1      0          0     0      0            a   \n",
              "1017207   1114          1      0          0     0      0            a   \n",
              "1017208   1115          1      0          0     0      0            a   \n",
              "\n",
              "         SchoolHoliday StoreType Assortment  ...  Promo2     PromoInterval  \\\n",
              "0                    1         c          a  ...       0               NaN   \n",
              "1                    1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "2                    1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "3                    1         c          c  ...       0               NaN   \n",
              "4                    1         a          a  ...       0               NaN   \n",
              "...                ...       ...        ...  ...     ...               ...   \n",
              "1017204              1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "1017205              1         c          c  ...       0               NaN   \n",
              "1017206              1         a          c  ...       0               NaN   \n",
              "1017207              1         a          c  ...       0               NaN   \n",
              "1017208              1         d          c  ...       1  Mar,Jun,Sept,Dec   \n",
              "\n",
              "         Year  Month  Day  WeekOfYear  SalesPerCustomer  SalesPerDistance  \\\n",
              "0        2015      7   31          31          0.001802          0.000787   \n",
              "1        2015      7   31          31          0.003200          0.003509   \n",
              "2        2015      7   31          31          0.003654          0.000212   \n",
              "3        2015      7   31          31          0.002670          0.006452   \n",
              "4        2015      7   31          31          0.008945          0.000167   \n",
              "...       ...    ...  ...         ...               ...               ...   \n",
              "1017204  2013      1    1           1          0.000000          0.584737   \n",
              "1017205  2013      1    1           1          0.000000          0.591489   \n",
              "1017206  2013      1    1           1          0.000000          0.120194   \n",
              "1017207  2013      1    1           1          0.000000          1.280460   \n",
              "1017208  2013      1    1           1          0.000000          0.208411   \n",
              "\n",
              "         CompetitionOpenSince  Promo2Since  \n",
              "0                     18072.0          NaN  \n",
              "1                     22077.0      26130.0  \n",
              "2                     24072.0      28154.0  \n",
              "3                     18081.0          NaN  \n",
              "4                      8060.0          NaN  \n",
              "...                       ...          ...  \n",
              "1017204               12084.0      62403.0  \n",
              "1017205                8024.0          NaN  \n",
              "1017206                   NaN          NaN  \n",
              "1017207                   NaN          NaN  \n",
              "1017208                   NaN      44264.0  \n",
              "\n",
              "[1017209 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cba8ac8c-c5f8-41ab-adf6-6aba14c1a692\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Customers</th>\n",
              "      <th>Open</th>\n",
              "      <th>Promo</th>\n",
              "      <th>StateHoliday</th>\n",
              "      <th>SchoolHoliday</th>\n",
              "      <th>StoreType</th>\n",
              "      <th>Assortment</th>\n",
              "      <th>...</th>\n",
              "      <th>Promo2</th>\n",
              "      <th>PromoInterval</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>WeekOfYear</th>\n",
              "      <th>SalesPerCustomer</th>\n",
              "      <th>SalesPerDistance</th>\n",
              "      <th>CompetitionOpenSince</th>\n",
              "      <th>Promo2Since</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5263</td>\n",
              "      <td>555</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.001802</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>18072.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6064</td>\n",
              "      <td>625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.003509</td>\n",
              "      <td>22077.0</td>\n",
              "      <td>26130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8314</td>\n",
              "      <td>821</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>24072.0</td>\n",
              "      <td>28154.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>13995</td>\n",
              "      <td>1498</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>18081.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4822</td>\n",
              "      <td>559</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.008945</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>8060.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017204</th>\n",
              "      <td>1111</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.584737</td>\n",
              "      <td>12084.0</td>\n",
              "      <td>62403.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017205</th>\n",
              "      <td>1112</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591489</td>\n",
              "      <td>8024.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017206</th>\n",
              "      <td>1113</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120194</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017207</th>\n",
              "      <td>1114</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.280460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017208</th>\n",
              "      <td>1115</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>d</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Mar,Jun,Sept,Dec</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44264.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1017209 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cba8ac8c-c5f8-41ab-adf6-6aba14c1a692')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cba8ac8c-c5f8-41ab-adf6-6aba14c1a692 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cba8ac8c-c5f8-41ab-adf6-6aba14c1a692');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7661fc0b-11a5-4de6-a1fc-d6d23cb5a82d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7661fc0b-11a5-4de6-a1fc-d6d23cb5a82d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7661fc0b-11a5-4de6-a1fc-d6d23cb5a82d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dcb65676-9764-4a89-a9b3-5bdd61623522\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dcb65676-9764-4a89-a9b3-5bdd61623522 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0556d0de",
      "metadata": {
        "id": "0556d0de",
        "outputId": "dc5aaa0f-3c6a-47ee-c4aa-ec7806d9eb9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1017209 entries, 0 to 1017208\n",
            "Data columns (total 21 columns):\n",
            " #   Column                Non-Null Count    Dtype  \n",
            "---  ------                --------------    -----  \n",
            " 0   Store                 1017209 non-null  int64  \n",
            " 1   DayOfWeek             1017209 non-null  int32  \n",
            " 2   Sales                 1017209 non-null  int64  \n",
            " 3   Customers             1017209 non-null  int64  \n",
            " 4   Open                  1017209 non-null  int64  \n",
            " 5   Promo                 1017209 non-null  int64  \n",
            " 6   StateHoliday          1017209 non-null  object \n",
            " 7   SchoolHoliday         1017209 non-null  int64  \n",
            " 8   StoreType             1017209 non-null  object \n",
            " 9   Assortment            1017209 non-null  object \n",
            " 10  CompetitionDistance   1014567 non-null  float64\n",
            " 11  Promo2                1017209 non-null  int64  \n",
            " 12  PromoInterval         509178 non-null   object \n",
            " 13  Year                  1017209 non-null  int32  \n",
            " 14  Month                 1017209 non-null  int32  \n",
            " 15  Day                   1017209 non-null  int32  \n",
            " 16  WeekOfYear            1017209 non-null  int64  \n",
            " 17  SalesPerCustomer      1017209 non-null  float64\n",
            " 18  SalesPerDistance      1014567 non-null  float64\n",
            " 19  CompetitionOpenSince  693861 non-null   float64\n",
            " 20  Promo2Since           509178 non-null   float64\n",
            "dtypes: float64(5), int32(4), int64(8), object(4)\n",
            "memory usage: 147.5+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a4c6b45",
      "metadata": {
        "id": "6a4c6b45"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532f2356",
      "metadata": {
        "id": "532f2356",
        "outputId": "e80a0ad3-000e-42fb-94c0-758deabc8db3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo',\n",
              "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
              "       'CompetitionDistance', 'Promo2', 'PromoInterval', 'Year', 'Month',\n",
              "       'Day', 'WeekOfYear', 'SalesPerCustomer', 'SalesPerDistance',\n",
              "       'CompetitionOpenSince', 'Promo2Since'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2780478b",
      "metadata": {
        "id": "2780478b",
        "outputId": "a8fbb59b-52e5-40ff-d96b-1a71cf8847a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Store  DayOfWeek  Sales  Customers  Open  Promo StateHoliday  \\\n",
              "0            1          4   5263        555     1      1            0   \n",
              "1            2          4   6064        625     1      1            0   \n",
              "2            3          4   8314        821     1      1            0   \n",
              "3            4          4  13995       1498     1      1            0   \n",
              "4            5          4   4822        559     1      1            0   \n",
              "...        ...        ...    ...        ...   ...    ...          ...   \n",
              "1017204   1111          1      0          0     0      0            a   \n",
              "1017205   1112          1      0          0     0      0            a   \n",
              "1017206   1113          1      0          0     0      0            a   \n",
              "1017207   1114          1      0          0     0      0            a   \n",
              "1017208   1115          1      0          0     0      0            a   \n",
              "\n",
              "         SchoolHoliday StoreType Assortment  ...  Promo2     PromoInterval  \\\n",
              "0                    1         c          a  ...       0               NaN   \n",
              "1                    1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "2                    1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "3                    1         c          c  ...       0               NaN   \n",
              "4                    1         a          a  ...       0               NaN   \n",
              "...                ...       ...        ...  ...     ...               ...   \n",
              "1017204              1         a          a  ...       1   Jan,Apr,Jul,Oct   \n",
              "1017205              1         c          c  ...       0               NaN   \n",
              "1017206              1         a          c  ...       0               NaN   \n",
              "1017207              1         a          c  ...       0               NaN   \n",
              "1017208              1         d          c  ...       1  Mar,Jun,Sept,Dec   \n",
              "\n",
              "         Year  Month  Day  WeekOfYear  SalesPerCustomer  SalesPerDistance  \\\n",
              "0        2015      7   31          31          0.001802          0.000787   \n",
              "1        2015      7   31          31          0.003200          0.003509   \n",
              "2        2015      7   31          31          0.003654          0.000212   \n",
              "3        2015      7   31          31          0.002670          0.006452   \n",
              "4        2015      7   31          31          0.008945          0.000167   \n",
              "...       ...    ...  ...         ...               ...               ...   \n",
              "1017204  2013      1    1           1          0.000000          0.584737   \n",
              "1017205  2013      1    1           1          0.000000          0.591489   \n",
              "1017206  2013      1    1           1          0.000000          0.120194   \n",
              "1017207  2013      1    1           1          0.000000          1.280460   \n",
              "1017208  2013      1    1           1          0.000000          0.208411   \n",
              "\n",
              "         CompetitionOpenSince  Promo2Since  \n",
              "0                     18072.0          NaN  \n",
              "1                     22077.0      26130.0  \n",
              "2                     24072.0      28154.0  \n",
              "3                     18081.0          NaN  \n",
              "4                      8060.0          NaN  \n",
              "...                       ...          ...  \n",
              "1017204               12084.0      62403.0  \n",
              "1017205                8024.0          NaN  \n",
              "1017206                   NaN          NaN  \n",
              "1017207                   NaN          NaN  \n",
              "1017208                   NaN      44264.0  \n",
              "\n",
              "[1017209 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abab99cd-7a4c-4e35-9b7d-1b768e00dd67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Customers</th>\n",
              "      <th>Open</th>\n",
              "      <th>Promo</th>\n",
              "      <th>StateHoliday</th>\n",
              "      <th>SchoolHoliday</th>\n",
              "      <th>StoreType</th>\n",
              "      <th>Assortment</th>\n",
              "      <th>...</th>\n",
              "      <th>Promo2</th>\n",
              "      <th>PromoInterval</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>WeekOfYear</th>\n",
              "      <th>SalesPerCustomer</th>\n",
              "      <th>SalesPerDistance</th>\n",
              "      <th>CompetitionOpenSince</th>\n",
              "      <th>Promo2Since</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>5263</td>\n",
              "      <td>555</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.001802</td>\n",
              "      <td>0.000787</td>\n",
              "      <td>18072.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>6064</td>\n",
              "      <td>625</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.003509</td>\n",
              "      <td>22077.0</td>\n",
              "      <td>26130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8314</td>\n",
              "      <td>821</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>24072.0</td>\n",
              "      <td>28154.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>13995</td>\n",
              "      <td>1498</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>18081.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4822</td>\n",
              "      <td>559</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>31</td>\n",
              "      <td>0.008945</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>8060.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017204</th>\n",
              "      <td>1111</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Jan,Apr,Jul,Oct</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.584737</td>\n",
              "      <td>12084.0</td>\n",
              "      <td>62403.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017205</th>\n",
              "      <td>1112</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>c</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591489</td>\n",
              "      <td>8024.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017206</th>\n",
              "      <td>1113</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120194</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017207</th>\n",
              "      <td>1114</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>a</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.280460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017208</th>\n",
              "      <td>1115</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>d</td>\n",
              "      <td>c</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>Mar,Jun,Sept,Dec</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44264.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1017209 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abab99cd-7a4c-4e35-9b7d-1b768e00dd67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abab99cd-7a4c-4e35-9b7d-1b768e00dd67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abab99cd-7a4c-4e35-9b7d-1b768e00dd67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cdecf971-0e85-4388-96b2-e14685fa9737\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdecf971-0e85-4388-96b2-e14685fa9737')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cdecf971-0e85-4388-96b2-e14685fa9737 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1decda08-2f15-4e8f-a480-71c6270d5dc5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1decda08-2f15-4e8f-a480-71c6270d5dc5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbff3887",
      "metadata": {
        "id": "fbff3887"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce72632a",
      "metadata": {
        "id": "ce72632a"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# Take a sample of 10,000 records for training and testing\n",
        "data_sample = data.sample(n=50000, random_state=42)\n",
        "# Split the whole dataset into features (X) and target (y)\n",
        "X = data_sample.drop(columns=['Sales'], axis=1)   # Features (dropping 'Sales', 'Date')\n",
        "y = data_sample['Sales']   # Target (Sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "969b6c5b",
      "metadata": {
        "id": "969b6c5b",
        "outputId": "959fb222-6e34-45ce-b6d4-c7ea13eb715f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape --  (36125, 20)\n",
            "y_train shape --  (36125,)\n",
            "X_train shape --  (6375, 20)\n",
            "y_train shape --  (6375,)\n",
            "X_test shape --  (7500, 20)\n",
            "y_test shape --  (7500,)\n"
          ]
        }
      ],
      "source": [
        "## Random split the dataset to two sets (train_set, test_set)\n",
        "## For validation ---  I will use Cross Validation\n",
        "# Take a sample of 10,000 records for training and testing\n",
        "data_sample = data.sample(n=50000, random_state=42)\n",
        "# Split the whole dataset into features (X) and target (y)\n",
        "X = data_sample.drop(columns=['Sales'], axis=1)   # Features (dropping 'Sales', 'Date')\n",
        "y = data_sample['Sales']   # Target (Sales)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, shuffle=True, random_state=42)\n",
        "X_train, X_vald, y_train, y_vald = train_test_split(X_train, y_train, test_size=0.15, shuffle=True, random_state=42)\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "\n",
        "## Check Shapes of these Sets\n",
        "print('X_train shape -- ', X_train.shape)\n",
        "print('y_train shape -- ', y_train.shape)\n",
        "print('X_train shape -- ', X_vald.shape)\n",
        "print('y_train shape -- ', y_vald.shape)\n",
        "print('X_test shape -- ', X_test.shape)\n",
        "print('y_test shape -- ', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6269c44d",
      "metadata": {
        "id": "6269c44d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0656612a",
      "metadata": {
        "id": "0656612a",
        "outputId": "278aa6cd-e327-4355-d604-7f7cda1d4089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Store                       0\n",
              "DayOfWeek                   0\n",
              "Customers                   0\n",
              "Open                        0\n",
              "Promo                       0\n",
              "StateHoliday                0\n",
              "SchoolHoliday               0\n",
              "StoreType                   0\n",
              "Assortment                  0\n",
              "CompetitionDistance        96\n",
              "Promo2                      0\n",
              "PromoInterval           18269\n",
              "Year                        0\n",
              "Month                       0\n",
              "Day                         0\n",
              "WeekOfYear                  0\n",
              "SalesPerCustomer            0\n",
              "SalesPerDistance           96\n",
              "CompetitionOpenSince    11473\n",
              "Promo2Since             18269\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DayOfWeek</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Customers</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Open</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Promo</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StateHoliday</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SchoolHoliday</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StoreType</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Assortment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CompetitionDistance</th>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Promo2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PromoInterval</th>\n",
              "      <td>18269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Day</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WeekOfYear</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalesPerCustomer</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SalesPerDistance</th>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CompetitionOpenSince</th>\n",
              "      <td>11473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Promo2Since</th>\n",
              "      <td>18269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb9af8d",
      "metadata": {
        "id": "3fb9af8d",
        "outputId": "b48b6f0b-636c-46ce-a6b0-f4648f047cd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 36125 entries, 999732 to 253854\n",
            "Data columns (total 20 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Store                 36125 non-null  int64  \n",
            " 1   DayOfWeek             36125 non-null  int32  \n",
            " 2   Customers             36125 non-null  int64  \n",
            " 3   Open                  36125 non-null  int64  \n",
            " 4   Promo                 36125 non-null  int64  \n",
            " 5   StateHoliday          36125 non-null  object \n",
            " 6   SchoolHoliday         36125 non-null  int64  \n",
            " 7   StoreType             36125 non-null  object \n",
            " 8   Assortment            36125 non-null  object \n",
            " 9   CompetitionDistance   36029 non-null  float64\n",
            " 10  Promo2                36125 non-null  int64  \n",
            " 11  PromoInterval         17856 non-null  object \n",
            " 12  Year                  36125 non-null  int32  \n",
            " 13  Month                 36125 non-null  int32  \n",
            " 14  Day                   36125 non-null  int32  \n",
            " 15  WeekOfYear            36125 non-null  int64  \n",
            " 16  SalesPerCustomer      36125 non-null  float64\n",
            " 17  SalesPerDistance      36029 non-null  float64\n",
            " 18  CompetitionOpenSince  24652 non-null  float64\n",
            " 19  Promo2Since           17856 non-null  float64\n",
            "dtypes: float64(5), int32(4), int64(7), object(4)\n",
            "memory usage: 5.2+ MB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228f2efb",
      "metadata": {
        "id": "228f2efb"
      },
      "source": [
        "# Pipline of Data for Deal nulls and scal data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16cf342",
      "metadata": {
        "scrolled": false,
        "id": "a16cf342",
        "outputId": "92e9cb7a-5f70-4953-8197-943a874f7469",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical Columns : \n",
            " ['Store', 'DayOfWeek', 'Customers', 'Open', 'Promo', 'SchoolHoliday', 'CompetitionDistance', 'Promo2', 'Year', 'Month', 'Day', 'WeekOfYear', 'SalesPerCustomer', 'SalesPerDistance', 'CompetitionOpenSince', 'Promo2Since']\n"
          ]
        }
      ],
      "source": [
        "## Separete the columns according to type (numerical or categorical)\n",
        "num_cols = [col for col in X_train.columns if X_train[col].dtype in ['float32', 'float64', 'int32', 'int64']]\n",
        "\n",
        "\n",
        "print('Numerical Columns : \\n', num_cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d62c0c",
      "metadata": {
        "id": "c3d62c0c"
      },
      "outputs": [],
      "source": [
        "# Define categorical and numerical columns\n",
        "\n",
        "num_cols_meadin =[ 'CompetitionDistance', 'SalesPerCustomer', 'SalesPerDistance', 'CompetitionOpenSince', 'Promo2Since']\n",
        "num_cols_mostfrq=['Store','DayOfWeek','Customers', 'Open', 'Promo', 'SchoolHoliday','Promo2', 'Year', 'Month', 'Day', 'WeekOfYear']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3892ad",
      "metadata": {
        "id": "9c3892ad",
        "outputId": "dc350fc2-6537-4c10-aa41-032b5fa9ba8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical Columns : \n",
            " ['StateHoliday', 'StoreType', 'Assortment', 'PromoInterval']\n"
          ]
        }
      ],
      "source": [
        "categ_cols = [col for col in X_train.columns if X_train[col].dtype not in ['float32', 'float64', 'int32', 'int64']]\n",
        "print('Categorical Columns : \\n', categ_cols)\n",
        "categ_cols_lable=['StateHoliday', 'StoreType','PromoInterval']\n",
        "categ_cols_onehot=[ 'Assortment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7ddfc7",
      "metadata": {
        "id": "0a7ddfc7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc8ee82",
      "metadata": {
        "id": "dfc8ee82"
      },
      "outputs": [],
      "source": [
        "# Define the pipeline for categorical columns with One-Hot Encoding\n",
        "categ_pipeline_Onehot = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
        "    ('onehot', OneHotEncoder( drop='first', handle_unknown='ignore'))  # One-hot encode categorical variables\n",
        "])\n",
        "\n",
        "# Custom transformer for Label Encoding\n",
        "def label_encode(X):\n",
        "    le = LabelEncoder()\n",
        "    return np.array([le.fit_transform(col) for col in X.T]).T\n",
        "\n",
        "categ_pipeline_Label = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
        "    ('label_encode', FunctionTransformer(label_encode, validate=False))  # Label encode categorical variables\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15eac33d",
      "metadata": {
        "id": "15eac33d"
      },
      "outputs": [],
      "source": [
        "# Define the pipeline for numerical columns\n",
        "num_pipeline_median = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
        "    ('scaler', StandardScaler())  # Standardize the numerical features\n",
        "])\n",
        "\n",
        "# Pipeline for numerical columns with most frequent imputation\n",
        "num_pipeline_most_frequent = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent value\n",
        "    ('scaler', StandardScaler())  # Standardize the numerical features\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0313e9b2",
      "metadata": {
        "id": "0313e9b2",
        "outputId": "fc342cd7-d139-4ba3-fc2a-9993704cc46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['full_pipeline.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Build the full pipeline with ColumnTransformer\n",
        "full_pipeline = ColumnTransformer(transformers=[\n",
        "    ('num_pipeline_median', num_pipeline_median, num_cols_meadin),  # Numerical pipeline\n",
        "    ('num_pipeline_most_frequent', num_pipeline_most_frequent, num_cols_mostfrq),  # Categorical pipeline\n",
        "    ('categ_pipeline_Onehot', categ_pipeline_Onehot, categ_cols_onehot),\n",
        "    ('categ_pipeline_Label', categ_pipeline_Label, categ_cols_lable) # Pipeline for 'Assortment'\n",
        "\n",
        "])\n",
        "joblib.dump(full_pipeline, 'full_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0236140",
      "metadata": {
        "id": "e0236140",
        "outputId": "2eebdac1-dfa4-48fd-b4ce-685db39028a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_prepared shape: (36125, 21)\n",
            "X_train_prepared shape: (6375, 21)\n",
            "X_test_prepared shape: (7500, 21)\n"
          ]
        }
      ],
      "source": [
        "# Apply the full pipeline to the training and test sets\n",
        "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
        "X_vald_prepared=full_pipeline.transform(X_vald)\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "# Check the resulting shape after transformation\n",
        "print('X_train_prepared shape:', X_train_prepared.shape)\n",
        "print('X_train_prepared shape:', X_vald_prepared.shape)\n",
        "print('X_test_prepared shape:', X_test_prepared.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672535b8",
      "metadata": {
        "scrolled": true,
        "id": "672535b8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a92a3655",
      "metadata": {
        "id": "a92a3655"
      },
      "source": [
        "# Model and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train_prepared, X_vald_prepared, y_train, and y_vald are already defined\n",
        "# Define the models with their respective hyperparameters\n",
        "models = {\n",
        "    'SGDRegressor': {\n",
        "        'model': SGDRegressor(),\n",
        "        'params': {\n",
        "            'loss': ['squared_error', 'huber'],\n",
        "            'alpha': [0.001, 0.01],\n",
        "            'penalty': ['elasticnet', 'l2'],\n",
        "            'learning_rate': ['adaptive', 'constant', 'invscaling'],\n",
        "            'max_iter': [1000, 2000],\n",
        "            'tol': [1e-4]\n",
        "        }\n",
        "    },\n",
        "    'KNeighborsRegressor': {\n",
        "        'model': KNeighborsRegressor(),\n",
        "        'params': {\n",
        "            'n_neighbors': [3, 5, 7],\n",
        "            'weights': ['uniform', 'distance'],\n",
        "            'algorithm': ['auto', 'ball_tree']\n",
        "        }\n",
        "    },\n",
        "    'XGBRegressor': {\n",
        "        'model': XGBRegressor(),\n",
        "        'params': {\n",
        "            'learning_rate': [0.1, 0.01],\n",
        "            'max_depth': [3, 5, 7],\n",
        "            'n_estimators': [100, 200],\n",
        "            'subsample': [0.8, 1.0],\n",
        "            'gamma': [0, 0.1]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize results and feature importance dictionary\n",
        "results = []\n",
        "feature_importances_dict = {}\n",
        "\n",
        "# Progress tracker variables\n",
        "total_models = len(models)\n",
        "current_model = 1\n",
        "\n",
        "# Loop to perform Grid Search on each model and evaluate\n",
        "for name, config in models.items():\n",
        "    print(f\"\\nStarting Grid Search for model: {name} ({current_model}/{total_models})\")\n",
        "    grid = GridSearchCV(config['model'], config['params'], scoring='neg_mean_squared_error', cv=3, verbose=2)\n",
        "    grid.fit(X_train_prepared, y_train)\n",
        "\n",
        "    # Log best parameters found\n",
        "    print(f\"Best parameters for {name}: {grid.best_params_}\")\n",
        "\n",
        "    # Get best estimator and predict\n",
        "    best_model = grid.best_estimator_\n",
        "    y_vald_pred = best_model.predict(X_vald_prepared)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mae = mean_absolute_error(y_vald, y_vald_pred)\n",
        "    mse = mean_squared_error(y_vald, y_vald_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_vald, y_vald_pred)\n",
        "\n",
        "    # Append the results\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Best Params': grid.best_params_,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'R²': r2\n",
        "    })\n",
        "\n",
        "    # Save the best model\n",
        "    model_filename = f\"{name}_best_model.pkl\"\n",
        "    joblib.dump(best_model, model_filename)\n",
        "    print(f\"Model {name} saved as {model_filename}\")\n",
        "\n",
        "    # Print evaluation metrics after each model finishes\n",
        "    print(f\"Evaluation for {name} - MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f} \\n'Best Params': {grid.best_params_}\")\n",
        "\n",
        "    # Update progress tracker\n",
        "    current_model += 1\n",
        "\n",
        "# Convert results to DataFrame for summary\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\nFinal Results Summary:\")\n",
        "print(df_results)\n",
        "\n"
      ],
      "metadata": {
        "id": "vSKSLNIAlQBI",
        "outputId": "99a5481d-db56-4322-f815-7af78418cd9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vSKSLNIAlQBI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Grid Search for model: SGDRegressor (1/3)\n",
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   5.7s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   4.8s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   5.9s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.9s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.8s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   6.2s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   4.6s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   4.6s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   4.2s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.001, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.5s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.0s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   5.1s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   4.8s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   4.0s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   3.9s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.5s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   4.2s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   5.8s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   4.2s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.001, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   3.9s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  14.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.001, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   9.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.4s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   6.6s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   5.5s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   6.3s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.9s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.6s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.7s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   6.9s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   5.7s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   6.6s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.7s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   3.0s\n",
            "[CV] END alpha=0.01, learning_rate=adaptive, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.7s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   6.4s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   9.3s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   6.7s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   2.5s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   3.1s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   5.0s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   5.2s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   6.9s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   5.2s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   2.9s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   3.8s\n",
            "[CV] END alpha=0.01, learning_rate=constant, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   3.0s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=1000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=   0.3s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.2s\n",
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=squared_error, max_iter=2000, penalty=l2, tol=0.0001; total time=   0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=elasticnet, tol=0.0001; total time=   8.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=1000, penalty=l2, tol=0.0001; total time=   4.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  16.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=elasticnet, tol=0.0001; total time=  18.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1616: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END alpha=0.01, learning_rate=invscaling, loss=huber, max_iter=2000, penalty=l2, tol=0.0001; total time=   8.8s\n",
            "Best parameters for SGDRegressor: {'alpha': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error', 'max_iter': 2000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
            "Model SGDRegressor saved as SGDRegressor_best_model.pkl\n",
            "Evaluation for SGDRegressor - MAE: 878.3774, MSE: 1519279.6317, RMSE: 1232.5906, R²: 0.8994 \n",
            "'Best Params': {'alpha': 0.001, 'learning_rate': 'adaptive', 'loss': 'squared_error', 'max_iter': 2000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
            "\n",
            "Starting Grid Search for model: KNeighborsRegressor (2/3)\n",
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV] END .....algorithm=auto, n_neighbors=3, weights=uniform; total time=   1.9s\n",
            "[CV] END .....algorithm=auto, n_neighbors=3, weights=uniform; total time=   1.8s\n",
            "[CV] END .....algorithm=auto, n_neighbors=3, weights=uniform; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=3, weights=distance; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=3, weights=distance; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=3, weights=distance; total time=   2.5s\n",
            "[CV] END .....algorithm=auto, n_neighbors=5, weights=uniform; total time=   2.7s\n",
            "[CV] END .....algorithm=auto, n_neighbors=5, weights=uniform; total time=   1.8s\n",
            "[CV] END .....algorithm=auto, n_neighbors=5, weights=uniform; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=5, weights=distance; total time=   2.4s\n",
            "[CV] END ....algorithm=auto, n_neighbors=5, weights=distance; total time=   2.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=5, weights=distance; total time=   2.7s\n",
            "[CV] END .....algorithm=auto, n_neighbors=7, weights=uniform; total time=   2.5s\n",
            "[CV] END .....algorithm=auto, n_neighbors=7, weights=uniform; total time=   1.8s\n",
            "[CV] END .....algorithm=auto, n_neighbors=7, weights=uniform; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=7, weights=distance; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=7, weights=distance; total time=   1.8s\n",
            "[CV] END ....algorithm=auto, n_neighbors=7, weights=distance; total time=   1.9s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=uniform; total time=  11.6s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=uniform; total time=  11.9s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=uniform; total time=  11.7s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=distance; total time=  11.6s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=distance; total time=  11.6s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=3, weights=distance; total time=  11.4s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=uniform; total time=  10.9s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=uniform; total time=  11.4s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=uniform; total time=  11.7s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=distance; total time=  11.7s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=distance; total time=  11.7s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=5, weights=distance; total time=  11.7s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=uniform; total time=  12.0s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=uniform; total time=  12.8s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=uniform; total time=  11.4s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=distance; total time=  10.8s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=distance; total time=  11.8s\n",
            "[CV] END algorithm=ball_tree, n_neighbors=7, weights=distance; total time=  11.7s\n",
            "Best parameters for KNeighborsRegressor: {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "Model KNeighborsRegressor saved as KNeighborsRegressor_best_model.pkl\n",
            "Evaluation for KNeighborsRegressor - MAE: 914.5610, MSE: 1946892.5076, RMSE: 1395.3109, R²: 0.8711 \n",
            "'Best Params': {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "\n",
            "Starting Grid Search for model: XGBRegressor (3/3)\n",
            "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   1.1s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   1.1s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   2.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   1.6s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.4s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.6s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   1.1s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.9s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   1.2s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   2.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   3.9s\n",
            "[CV] END gamma=0, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=   3.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   2.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   0.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.1s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=   1.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.2s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.7s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.8s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   3.0s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   2.3s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8; total time=   1.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.4s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
            "[CV] END gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0; total time=   1.5s\n",
            "Best parameters for XGBRegressor: {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Model XGBRegressor saved as XGBRegressor_best_model.pkl\n",
            "Evaluation for XGBRegressor - MAE: 365.0302, MSE: 325228.3186, RMSE: 570.2879, R²: 0.9785 \n",
            "'Best Params': {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
            "\n",
            "Final Results Summary:\n",
            "                 Model                                        Best Params  \\\n",
            "0         SGDRegressor  {'alpha': 0.001, 'learning_rate': 'adaptive', ...   \n",
            "1  KNeighborsRegressor  {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...   \n",
            "2         XGBRegressor  {'gamma': 0, 'learning_rate': 0.1, 'max_depth'...   \n",
            "\n",
            "          MAE           MSE         RMSE        R²  \n",
            "0  878.377376  1.519280e+06  1232.590618  0.899419  \n",
            "1  914.561044  1.946893e+06  1395.310900  0.871110  \n",
            "2  365.030175  3.252283e+05   570.287926  0.978469  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "qVl8wQnB6nH7"
      },
      "id": "qVl8wQnB6nH7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Sort the DataFrame by RMSE to make the plot more interpretable\n",
        "df_results_sorted = df_results.sort_values(by='RMSE')\n",
        "\n",
        "# Create a bar plot for RMSE of each model\n",
        "sns.barplot(x='RMSE', y='Model', data=df_results_sorted, palette='viridis')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Comparison of Models based on RMSE', fontsize=16)\n",
        "plt.xlabel('Root Mean Squared Error (RMSE)', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d_aEngoMn0KJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "d87383a4-b9f7-4baa-d352-32b56a0be733"
      },
      "id": "d_aEngoMn0KJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d=pd.DataFrame(X_train_prepared)\n"
      ],
      "metadata": {
        "id": "GaAJprDxuDQr"
      },
      "id": "GaAJprDxuDQr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUcpBqC--3-3"
      },
      "id": "FUcpBqC--3-3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}